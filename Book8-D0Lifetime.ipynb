{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<CENTER><img src=\"images/logos3.png\" style=\"width:30%\"></CENTER>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $D^0 \\rightarrow K^- \\pi^+$ decays: calculating the lifetime measurement <a name=\"c\"></a>\n",
    "\n",
    "\n",
    "In the following analysis we aim to obtain the lifetime measurement of [$D^{0}$](https://en.wikipedia.org/wiki/D_meson) mesons decaying into a kaon and a pion with opposite charge.\n",
    "\n",
    "The $D^{0}$ meson is composed of a $c$ quark and an $\\bar{u}$ antiquark (as we've seen in the Introduction to Particle Physics notebook) and among all the possible routes, it can decay to the final state $K^-\\pi^+$. The kaon is composed of $u$ quark and an $\\bar{s}$ antiquark and the pion is composed of a $u$ quark and an $\\bar{d}$ antiquark. These particles have lifetime which are long enough that, for the purpose of this\n",
    "exercise, they are stable within the LHCb detector.\n",
    "\n",
    "\n",
    "Let's start with understanding the idea of a decay process.\n",
    "\n",
    "We want to find $D^{0}$ mesons, but they don't live long enough to actually see with the detector itself. Instead, we have to **reconstruct** them from their decay products. We don't particularly mind where the $D^{0}$s themselves come from. All you need to know here is that each time the LHC smashes two protons together, they produce lots and lots of particles, some of which are $D^{0}$s.\n",
    "\n",
    "\n",
    "From theory, we know that there are several decay routes as you can see in [here](https://pdglive.lbl.gov/Particle.action?init=0&node=S032&home=MXXX035#decayclump_C) but today we are interested in the particular decay route $D^{0} \\to K^{-} \\pi^{+}$.\n",
    "\n",
    "\n",
    "In this option, a random $D^{0}$ emerges from the collision aftermath in the LHC (we don't care how) can decay directly to $K^-\\pi^+$ with opposite charge. The decay happens at the vertex below, where the $D^0$ blue line changes to a kaon and pion lines (purple and red respectively). We denote a kaon by the letter $K^{-}$ and a pion by $\\pi^+$, with their respective charges on top. \n",
    "\n",
    "<figure>\n",
    "    <center> <img src=\"images/D0-decay.png\" alt=\"image missing\" style=\"width:40%\" />\n",
    "   <figcaption>Image 1: The $D^0$ decay directly from the proton-proton collision. &copy; <a href=\"https://reader.elsevier.com/reader/sd/pii/S2405601415006811?token=6FB63C7A4CA7A9942923D4464E1D0026C06C3D8B7F2480E5D95FAAE090160896368E92EBE888890A4213BCF7055A7856&originRegion=eu-west-1&originCreation=20221101130344\">LHCb Masterclass</a> [1]</figcaption> </center>\n",
    "</figure>\n",
    "\n",
    "Now that we know about 4-vectors from Notebook 4 and we know how to manipulate them, we will look at the $D^{0}$ decay to $K^- \\pi^+$ but firstly, we need to discuss what is the liferime and how we measure it in our decay of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contents:**\n",
    "- [Introduction](#0.)\n",
    "- [Lifetime](#1.)\n",
    "- [The invariant mass calculation](#2.)\n",
    "- [Cuts](#3.)\n",
    "- [Over to you! To four leptons](#3.)\n",
    "- [Real experiments](#4.)\n",
    "- [Extension exercises](#5.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a name=\"0.\"></a>\n",
    "\n",
    "The Large Hadron Collider (LHC) is not only a tool with which to search for exotic new particles,\n",
    "but also a factory of particles whose existence is in no doubt but whose precise properties are not\n",
    "yet known well enough. One example are charmed hadrons, i.e. hadrons which contain a charm\n",
    "(also known as *c*) quark, which were first discovered more than 30 years ago. Approximately one in\n",
    "every ten LHC interactions produces a charmed hadron, and the LHCb experiment at the LHC has\n",
    "already recorded over one billion signal events in various decay channels.\n",
    "\n",
    "Even though the LHC produces a lot of charmed hadrons, it produces a much greater number of\n",
    "other particles which can be mistaken for the signal (“backgrounds”). In order to extract information\n",
    "from such large signal samples, it is necessary to achieve excellent control over these backgrounds.\n",
    "This set of exercises is designed to teach you how to:\n",
    "\n",
    "1. Fit functional forms for the signal and background to the data in order to measure the number\n",
    "of signal events in the data sample and their purity (defined as the fraction of signal events in\n",
    "the total sample).\n",
    "2. Obtain the distribution of signal events in a given variable by taking the combined distribution of\n",
    "events in the data sample (which contains both signal and background events) and subtracting\n",
    "the background distribution. The result of the fit in the previous step is used to find a sample\n",
    "of pure background events for subtraction, and to compute from the signal yield and purity the\n",
    "appropriate amount of background which should be subtracted.\n",
    "3. Reduce the amount of background contamination by placing requirements on these variables\n",
    "which exclude the background dominated regions, using the signal and background distributions\n",
    "obtained previously.\n",
    "4. The signal you will be looking at decays exponentially with time, analogously to say a radioactive\n",
    "isotope. You can now use the sample of events passing the previous step to measure the\n",
    "“lifetime” of the signal particle. The lifetime is defined as the time taken for $(e − 1)/e$ of the\n",
    "signal events to decay, where $e \\sim 2.718$ is the base of the natural logarithm. It is analogous\n",
    "to the concept of half-life in radioactive decay."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lifetime <a name=\"1.\"></a>\n",
    "\n",
    "\n",
    "\n",
    "The data sample we are going to use for this notebook consists of candidates for the $D^0$ meson found in a sample randomly collected by the LHCb detector during the 2012 data-taking period. \n",
    "\n",
    "The LHCb detector can measure the momentum and energy of muons coming out of decays, and you can access that information quite simply. We mentioned earlier that each smash makes lots of particles. That's true - in fact, it makes so many that we can't actually store all the records of what happened, even on some of the biggest data storage facilities in the world. Therefore, we select only events that are interesting to us, in particular, we want to see exactly **one kaon and one pion** in the final state.\n",
    "\n",
    "\n",
    "The $D^0$ particles have a distinctive feature and that is their measurably long lifetime. The average lifetime is $4 \\cdot 10^{-13}$ seconds. \n",
    "\n",
    "It travels increadibly fast, actually nearly at the speed of light at LHCb (typically $\\nu \\sim 0.99919 \\cdot c$). If you remember from your basic newtonian physics course, to calculate the average distance we would take our velocity and multiply it by the time but, since our particle travels at very high speed, we need to take into account relativistic effects. Therefore, the average distance travelled is expected to be:\n",
    "\n",
    "<CENTER> $0.4 \\beta \\gamma c = 3$mm </CENTER>\n",
    "\n",
    "where $\\gamma$ is the Lorentz factor.\n",
    "\n",
    "<div class=\"alert alert-warning\"> If you don't know about special relativity, don't worry! What we need to know is that when we are dealing with increadibly fast particles travelling along our detector, we need to include this information and the way we do it is adjusting our expressions with the Lorentz factor.\n",
    "</div>\n",
    "\n",
    "Fast mesons live longer, thus a lifetime at rest of 0.4ps means a lifetime inside the experiment of about 10ps or even longer. Another possible process is when the $D^0$ appears as a child of a $B$ particle. In this case we can measure the displacement which we are going to call the *impact parameter (IP)*. The IP is defined as the perpendicular distance between the path of our $D^0$ particle and the center of the collision. \n",
    "\n",
    "\n",
    "<figure>\n",
    "    <center> <img src=\"images/B-D0-decay.png\" alt=\"image missing\" style=\"width:40%\" />\n",
    "   <figcaption>Image 2: Secondary verteces displaced from the proton-proton collision. &copy; <a href=\"https://reader.elsevier.com/reader/sd/pii/S2405601415006811?token=6FB63C7A4CA7A9942923D4464E1D0026C06C3D8B7F2480E5D95FAAE090160896368E92EBE888890A4213BCF7055A7856&originRegion=eu-west-1&originCreation=20221101130344\">LHCb Masterclass</a> [1]</figcaption> </center>\n",
    "</figure>\n",
    "\n",
    "When we are dealing with the case where the $D^0$ is produced directly from the proton-proton collisions (as in Image 1), the IP is small, but when it comes as a child of the $B$ meson, the IP is large. This fact, together with their abundant production, allows the $D^0$ signals to be well separated from the background of the underlying event, most of which consists of random combinations of particles produced in the proton-proton collision.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have to open the data that we want to analyze. As described earlier, the data is stored in a *.root file. We can use a python library called uproot to access the data. Below is an example of how to open a *.root file using uproot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data file\n",
    "import uproot\n",
    "f = uproot.open(\"../LHCb_data/D02KPi/MasterclassData_2012.root\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the contents of a file by using the method keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we have an object called 'DecayTree'. We can obtain information about the object in the file and its type by using the method classnames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.classnames()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the object called DecayTree is a TTree type. A TTree is simply columns of data stored in the .root format. Each column of data can represent a different physical quantity of a particle. For instance, its charge, energy, momentum etc.\n",
    "\n",
    "Now we know what data the file contains, in future we can quickly access that data. We want to access the DecayTree data. This can be done by executing the command below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = uproot.open(\"../LHCb_data/D02KPi/MasterclassData_2012.root:DecayTree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at contents of the TTree. Essentially all the columns in the TTree called DecayTree. Within this tree, you will see\n",
    "three particles : D0, kaon, and pion, as well as some other quantities which are not of immediate\n",
    "interest for this exercise. All information which you need to successfully complete this exercise is\n",
    "contained in Leaves of the DecayTree whose names begin with the name of one of these three\n",
    "particles. The only exception is the number of proton-proton interactions in the event, “nPV”,\n",
    "which will be used in the last exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These names might not be very clear so let's talk about the ones that are going to be important for us:\n",
    "\n",
    "* `D0_MM`: this is the invariant mass of the $D^0$ meson. The signal can be seen as a peaking structure rising\n",
    "above a flat background. The range of masses relevant for this analysis is 1816-1914 MeV. A\n",
    "few poorly measured events lie outside this range which can be neglected.\n",
    "\n",
    "* `D0_TAU`: this is the distribution of decay times of the $D^0$ candidates. The signal is described by a\n",
    "single exponential whose slope is the $D^0$ lifetime (the object of the last exercise), while the\n",
    "background concentrates at short decay times.\n",
    "\n",
    "* `D0_MINIPCHI2`: this is the smallest $\\chi^2$ of the $D^0$ impact parameter with respect to any proton-proton interaction\n",
    "in the event. The smaller the impact parameter $\\chi^2$, the more likely it is that the $D^0$ actually\n",
    "came from that primary interaction. This variable is always positive, and is small for the signal\n",
    "and large for the background.\n",
    "\n",
    "* `D0_PT`: this is the momentum of the $D^0$ transverse to the LHC beamline. This is a good background\n",
    "discriminant as you will discover in exercises two and three.\n",
    "\n",
    "* `D0_DIRA_OWNPV`: this is the cosine of the angle between the $D^0$ momentum vector and the vector between\n",
    "the primary proton-proton interaction vertex and the decay vertex of the $D^0$. This variable\n",
    "is close to 1 for the signal (as these two vectors coincide for the signal within the effects of\n",
    "experimental resolution), and is smaller for the background (as the vectors do not coincide,\n",
    "since the background does not come from the primary interaction).\n",
    "\n",
    "* `nPV`: this is the number of proton-proton interactions in the event. If an event contains more than\n",
    "one proton-proton interaction, it is necessary to associate the $D^0$ candidate to one of the\n",
    "interactions in order to measure the $D^0$ decay time and pointing angle. The convention used\n",
    "in this ntuple is that the primary interaction associated to the $D^0$ candidate is the one with\n",
    "respect to which the $D^0$ has the smallest impact parameter."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the $D^0$ mass distribution! <a name=\"4.\"></a>\n",
    "\n",
    "Now that we've learned about the variables, we are ready to plot and fit the invariant mass! The first step will be to put all of our data in a `DataFrame`, which is quite similar to an Excel spreadsheed, including all the variables we are going to work with. To create our DataFrame we will use the option `library=\"pd\"` when creating our arrays.\n",
    "\n",
    "Let's start with plotting the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hist\n",
    "from hist import Hist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load data into DataFrame structure\n",
    "# Here we are selecting the variables we want in the columns of our 'table' \n",
    "D0_df = events.arrays([\"D0_MM\",\"D0_TAU\",\"D0_PT\",\"D0_MINIPCHI2\",\"D0_MINIP\"],library=\"pd\")\n",
    "\n",
    "# View the first 10 rows of the table, which correspond to the first 10 events in our root file\n",
    "D0_df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here you can see for each entry the respective values of mass, decay time, transverse momentum and IP chi2. Let's now plot the mass distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the histogram\n",
    "hist_mD0 = Hist(hist.axis.Regular(100,1810,1910, label = \"$m(K^+ \\pi^-)$ (MeV)\"))\n",
    "\n",
    "# Fill the histogram with the mass values form the DataFrame and plot\n",
    "mD0 = D0_df[\"D0_MM\"]\n",
    "hist_mD0.fill(mD0)\n",
    "hist_mD0.plot(histtype = \"fill\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "__Congratulations!__ You have just plotted the $K^- \\pi^+$ invariant mass!\n",
    "    \n",
    "</div>\n",
    "\n",
    "As you can see, there is a clear peak centered at around 1865GeV. Any ideas what is this peak?\n",
    "\n",
    "\n",
    "<details>\n",
    "    <summary>Answer: </summary>\n",
    "        That's right, it's the $D^0$ meson which has a mass of 1865 GeV!\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to contents](#c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the mass peak <a name=\"5.\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have reconstructed the $D^0$ mass, the next step is to fit the histogram. To fit the histogram is to try to find the best function, (or combination of funtions) that reproduce the shape we see in our data. Let's start with a simple example. \n",
    "\n",
    "Imagine we have a set of data points and we want to find a line that passes nearby our points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#define data\n",
    "x = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n",
    "y = np.array([2, 5, 6, 7, 9, 12, 16, 19])\n",
    "\n",
    "#find line of best fit\n",
    "a, b = np.polyfit(x, y, 1)\n",
    "\n",
    "#add points to plot\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "\n",
    "#add line of best fit to plot\n",
    "plt.plot(x, a*x+b, c=\"red\")       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our plot, the blue dots represent our data and the red line is the best line we can draw that reproduces the behavior of our data. Our LHCb data is not as simple as this example, but the idea is the same! We want to find the best curve that reproduces the shape of the mass distribution we found. It won't be a straight line as our data does not have this kind of pattern, but there are other types of functions that we can use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian function\n",
    "\n",
    "One very commonly used is the Gaussian function (also known as the normal distribution). We can represent it by the function:\n",
    "\n",
    "$f(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\frac{1}{2} \\big(\\frac{x-\\mu}{\\sigma}\\big)^2}$\n",
    "\n",
    "And if we want to draw this function, we can run the following line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## generate the data and plot it for a gaussian curve\n",
    "\n",
    "## x-axis for the plot\n",
    "x_data = np.arange(-5, 5, 0.001)\n",
    "\n",
    "## y-axis as the gaussian\n",
    "y_data = stats.norm.pdf(x_data, 0, 1)\n",
    "\n",
    "## plot data\n",
    "plt.plot(x_data, y_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting... it looks like this gaussian function has some similarities with the mass peak we found! So perhaps we can use this Gaussian function in our fit to the mass peak. When dealing with gaussian functions, two very important features are the mean value of the function, $\\mu$, and the width, $\\sigma$. The $\\mu$ is the value which our curve is cetered at, in this case, the gaussian peak is centered at zero. The $\\sigma$ is the width of the distrbution, in this case we can see that the distribution is basically over before -2 and after 2. So the total width here is 1.\n",
    "\n",
    "<div class=\"alert alert-warning\"> Don't worry if the function has a complicated mathematical expression, the idea here is that since it looks a lot like our peak, we can use this function to learn features of our data!\n",
    "</div>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! It seems that our mass peak looks like a gaussian centered at around 1865 MeV and outside this gaussian, the distribution looks like a horizontal line.\n",
    "\n",
    "The gaussian-like behavior represents the $D^0 \\to K^- \\pi^+$ candidates, our signal events, and the events in this flat horizontal distribution are called background events. Signal events are the ones corresponding to our process of interest, while background events correspond to processes that we are not interested in. In this case, they correspond to combinatorial background.\n",
    "\n",
    "With all that said, we are ready to fit our invariant mass distribution!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1.) Necessary imports.    \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# 2.) Define fit function: Gaussian + straight line\n",
    "def fit_function(x, A, B, C, mu, sigma):\n",
    "    return (A*x + B + C * np.exp(-1.0 * (x - mu)**2 / (2 * sigma**2)))\n",
    "\n",
    "# 3.) Define bins and bin centers\n",
    "bins = np.linspace(1810, 1910, 100)\n",
    "binscenters = np.array([0.5 * (bins[i] + bins[i+1]) for i in range(len(bins)-1)])\n",
    "\n",
    "# 4.) Save the number of events per bin, and the bin values to arrays:\n",
    "# count and value are basically aliases\n",
    "x = hist_mD0.axes.centers[0]\n",
    "y = hist_mD0.counts()\n",
    "\n",
    "# 5.) Fit the function to the histogram data.\n",
    "\n",
    "# To perform a fit we first need to set initial values for the parameters in our function, usually we guess \n",
    "# the initial values for our parameters and we let the fit find the optimal values for each one\n",
    "INITIAL_GUESS = [0, 300, 1000, 1865, 5] # Remember that we have 5 parameters to set, so we need something like [A, B, C, mu, sigma]\n",
    "\n",
    "popt, pcov = curve_fit(fit_function, xdata=x, ydata=y, p0=INITIAL_GUESS)\n",
    "print(popt)\n",
    "error = np.sqrt(np.diag(pcov))\n",
    "\n",
    "# 6.) Generate enough x values to make the curves look smooth.\n",
    "xspace = np.linspace(1810, 1910, 100000)\n",
    "\n",
    "# Plot mass distribution\n",
    "hist_mD0.plot(histtype = \"fill\",label=r'Data')\n",
    "\n",
    "# Plot fit line\n",
    "plt.plot(xspace, fit_function(xspace, *popt), color='darkorange', linewidth=2.5, label=r'Fitted function')\n",
    "\n",
    "# Setting labels\n",
    "plt.xlabel(r'$m(K^- \\pi^+)$ (MeV)')\n",
    "plt.ylabel(r'Number of entries')\n",
    "plt.title(r'Invariant mass fit')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The mean value and the uncertainties from the fit\")\n",
    "\n",
    "mean_value = \"mu = {} +- {}\".format(popt[3], error[3])\n",
    "sigma_value = \"sigma = {} +- {}\".format(popt[4], error[4])\n",
    "print(mean_value)\n",
    "print(sigma_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "__Congratulations!__ you have just fitted the $D^0$ invariant mass distribution!\n",
    "    \n",
    "</div>\n",
    "\n",
    "Look at the fitted mass distribution. You can split it into three regions: \n",
    "\n",
    "* **Signal region**: region which contains mostly signal events (and also background events under the signal peak, which means that these background events behave like signal events)\n",
    "\n",
    "* **Background-only “sidebands”**: These are regions which we only have events that are not interesing for us, *i.e.*, background events. We are also going to define two of these sidebands, one above the signal (the upper sideband) and one below the signal (the lower sideband). \n",
    "\n",
    "Once you reach this step of the exercise, discuss how to define these sideband regions, and in particular how to define a region of pure background\n",
    "events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining signal variable distributions  <a name=\"5.\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we can think more carefully about the signal and background regions from our fit. The reason for worrying about this is because, to measure the $D^0$ lifetime properly, we need to get rid of these background events that lie under the signal peak. Even though they behave like signal events, they are not trully signals, therefore having these background events will lead to **incorrect measurements**!\n",
    "\n",
    "Let's define our peak (signal) to be almost fully contained in the window $[1840-1890]$MeV.\n",
    "\n",
    "In particular, an interval of $\\pm1\\sigma$ around the mean value contains 68% of the signal, while $\\pm3\\sigma$ contains 99.7% of the signal. So, if $\\sigma=7.6, \\pm3\\sigma = 22.8$ which corresponds to the limits: $1866.5-22.8 = 1843.7$ and $1866.5+22.8 = 1889.3$.\n",
    "\n",
    "Inside this window we have a mixture of signal and background events, but outside this window, we only have background events! Therefore, we can use these background sidebands to remove background events inside the signal region.\n",
    "\n",
    "\n",
    "Let's plot again our mass distribution and also vertical lines to create our distinct regions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mass distribution\n",
    "hist_mD0.plot(histtype = \"fill\",label=r'Data')\n",
    "\n",
    "# Plot fit line\n",
    "plt.plot(xspace, fit_function(xspace, *popt), color='darkorange', linewidth=2.5, label=r'Fitted function')\n",
    "\n",
    "# Plot vertical lines\n",
    "plt.axvline(1844,0, color='red')\n",
    "plt.axvline(1889,0, color='red')\n",
    "plt.xlim(1810,1920)\n",
    "\n",
    "# Setting labels\n",
    "plt.xlabel(r'$m(K^- \\pi^+)$ (MeV)')\n",
    "plt.ylabel(r'Number of entries')\n",
    "plt.title(r'Invariant mass fit')\n",
    "\n",
    "# Writing region labels\n",
    "plt.text(1837, 1600, '1', fontsize=16, color='red', bbox=dict(facecolor='white', alpha=0.8))\n",
    "plt.text(1882, 1600, '2', fontsize=16, color='red', bbox=dict(facecolor='white', alpha=0.8))\n",
    "plt.text(1913, 1600, '3', fontsize=16, color='red', bbox=dict(facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this plot, we've divided the mass distribution into 3 regions: *Signal-only* (2) and *Background-only* (1,3) events! Now we are ready for the next step.\n",
    "\n",
    "\n",
    "Our next step is what we call **background subtraction**. In particular we want to plot distributions of other variables for signal events only.\n",
    "\n",
    "In the previous exercise, you finished by definining a signal region, in which the events were a mixture of signal and background, and a sideband region of\n",
    "pure background events. You can now obtain the distribution of signal events in any given variable by subtracting the distributons found in the signal and sideband regions.\n",
    "\n",
    "We can also check the variables such as transverse momentum and impact parameter, for signal and background regions.\n",
    "\n",
    "For each of the variables listed in the Introduction, let's plot the background subtracted signal distributions. Overplot the background distributions from the sideband region on the same canvas, in order to easily compare the two. If the signal and background distributions look very similar to each other in any variable, let's plot that variable on a logarithmic scale to bring out the differences.\n",
    "\n",
    "To create these plots we will again use our table that we created before. We are going to filter the relevant events for each scenario with the command `.query`. Remember that the signal region contains event in the region [1840,1890]MeV, and the background regions contains events outside this window, which means either smaller than 1840 or greater than 1890."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame for the signal region\n",
    "D0_sig = D0_df.query(\"D0_MM>1840 & D0_MM<1890\")\n",
    "\n",
    "# Creating a DataFrame for the background region\n",
    "D0_bkg = D0_df.query(\"D0_MM<1840 | D0_MM>1890\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View first 5 rows of the signal table\n",
    "D0_sig.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View first 5 rows of the background table\n",
    "D0_bkg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've splitted the mass distribution into signal and background regions, let's plot the mass distribution for each scenario. For signal events only we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the signal region histogram\n",
    "hist_mD0_sig = Hist(hist.axis.Regular(100,1810,1910, label = \"$m(K^+ \\pi^-)$ (MeV)\"))\n",
    "\n",
    "# Fill and plot it\n",
    "mD0_sig = D0_sig[\"D0_MM\"]\n",
    "hist_mD0_sig.fill(mD0_sig)\n",
    "\n",
    "hist_mD0_sig.plot(histtype = \"fill\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that only the peak appears! We've just removed the evets outside this peak. Let's do the same exercise but now we plot only the background region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the background region histogram\n",
    "hist_mD0_bkg = Hist(hist.axis.Regular(100,1810,1910, label = \"$m(K^+ \\pi^-)$ (MeV)\"))\n",
    "\n",
    "# Fill and plot it\n",
    "mD0_bkg = #COMPLETE\n",
    "hist_mD0_bkg.fill#COMPLETE\n",
    "\n",
    "hist_mD0_bkg.plot(histtype = \"fill\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazing! Now we are only looking at the background events. Remember that our table not only contains the mass events, but also the other variables we saved. This means that we can also look at other variables in each region we defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D0_sig.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, let's plot other the $p_T$ distribution for both signal and background events!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating histograms for the pT signal and background only distributions\n",
    "hist_pt_sig = Hist(hist.axis.Regular(100,2000,12500, label = \"D0 PT (MeV)\"))\n",
    "hist_pt_bkg = Hist(hist.axis.Regular(100,2000,12500, label = \"D0 PT (MeV)\"))\n",
    "\n",
    "# Filling the histograms\n",
    "pt_sig = #COMPLETE # signal events\n",
    "pt_bkg = #COMPLETE # background events\n",
    "hist_pt_sig.fill#COMPLETE\n",
    "hist_pt_bkg.fill#COMPLETE\n",
    "\n",
    "# Plotting the histograms\n",
    "hist_pt_sig.plot(histtype = \"fill\",label=r'Signal')\n",
    "hist_pt_bkg.plot(histtype = \"fill\",label=r'Background')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your turn!**\n",
    "\n",
    "Plot the signal and background distributions for the `D0_MINIP` and `D0_TAU` variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating histograms for the pT signal and background only distributions\n",
    "hist_ip_sig = Hist(hist.axis.Regular(100,-4,2, label = \"D0_MINIP (MeV)\"))\n",
    "hist_ip_bkg = Hist(hist.axis.Regular(100,-4,2, label = \"D0_MINIP (MeV)\"))\n",
    "\n",
    "# Filling the histograms\n",
    "ip_sig = #COMPLETE\n",
    "ip_bkg = #COMPLETE\n",
    "hist_ip_sig.fill(np.log10(ip_sig))\n",
    "hist_ip_bkg.fill(np.log10(ip_bkg))\n",
    "\n",
    "# Plotting the histograms\n",
    "hist_ip_sig.plot(histtype = \"fill\",label=r'Signal')\n",
    "hist_ip_bkg.plot(histtype = \"fill\",label=r'Background')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating histograms for the pT signal and background only distributions\n",
    "hist_tau_sig = Hist(hist.axis.Regular(100,0,0.005, label = \"D0 TAU (MeV)\"))\n",
    "hist_tau_bkg = Hist(hist.axis.Regular(100,0,0.005, label = \"D0 TAU (MeV)\"))\n",
    "\n",
    "# Filling the histograms\n",
    "tau_sig = #COMPLETE\n",
    "tau_bkg = #COMPLETE\n",
    "hist_tau_sig.fill#COMPLETE\n",
    "hist_tau_bkg.fill(#COMPLETE\n",
    "\n",
    "# Plotting the histograms\n",
    "hist_tau_sig.plot(histtype = \"fill\",label=r'Signal')\n",
    "hist_tau_bkg.plot(histtype = \"fill\",label=r'Background')\n",
    "plt.legend(loc='best')\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've seen the signal and background distributions, we can perform our background subtraction technique! \n",
    "\n",
    "The idea is that we will subtract the background region from the signal region."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the $D^0$ lifetime  <a name=\"5.\"></a>\n",
    "\n",
    "Now we want to use the signal sample which you obtained in the previous step to\n",
    "measure the lifetime of the $D^0$ meson. This is the same quantity as the half-life of a radioactive\n",
    "particle : the $D^0$ decays according to an exponential distribution, and if this exponential is fitted to\n",
    "a distribution of the $D^0$ decay times, the slope of this exponential is the lifetime of the $D^0$.\n",
    "We will plot the decay time distribution of the background in the sideband region\n",
    "which you defined before. Fit this with a single exponential and measure the signal\n",
    "lifetime.\n",
    "\n",
    "First let's define our function that we will use in the fit. It will be a decreasing exponential function as you will see our lifetime will behave like that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_function(x, slope, A):\n",
    "    return A*np.exp(-slope*x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to measure our lifetime from our signal events, we need to differentiate what events are signal like, and which ones are background-like. For that we will create a new column in our table called `EvtType` which we will assign a EvtType of +1 for all the signal events, and a EvtType -1 for all the background events. To do that we will use the command `assign()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning EvtType to signal events\n",
    "D0_sig = D0_sig.assign(EvtType=+1)\n",
    "D0_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning EvtType to background events\n",
    "D0_bkg = D0_bkg.assign(EvtType=-1)\n",
    "D0_bkg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will merge our two tables (signal and background) into one with the command `concat()` in order to have all our events in a single table. Note that the events with `EvtType=1` are signal events, and events with `EvtType=-1` are background events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "D0_full = pd.concat([D0_sig, D0_bkg])\n",
    "D0_full"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to plot our decay time column with the *background subtracted*. We will plot the time variable but this time we will use the options called `weights` in our plotting command line. By using this option we are assigning the weights we've just created for signal and background events. Since our backgorund events have a weight of -1, our plot will represent the signal decay time distribution. To see the details more clear, we will also plot in a log scale!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal + background distribution\n",
    "D0_full[\"D0_TAU\"].plot(kind=\"hist\",bins=60, range=[0,0.01])\n",
    "\n",
    "# Background subtracted distribution (signal only)\n",
    "D0_full[\"D0_TAU\"].plot(kind=\"hist\",bins=60, range=[0,0.01], weights=D0_full[\"EvtType\"])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are finally ready to measure the $D^0$ lifetime! To obtain the lifetime measurement, we will fit this distribution with an exponential function and extract the slope. But first, let's just understand what it means to fit a distribution.\n",
    "\n",
    "To fit the histogram is to try to find the best function, (or combination of funtions) that reproduce the shape we see in our data. Let's start with a simple example. \n",
    "\n",
    "Imagine we have a set of data points and we want to find a line that passes nearby our points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#define data\n",
    "x = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n",
    "y = np.array([2, 5, 6, 7, 9, 12, 16, 19])\n",
    "\n",
    "#find line of best fit\n",
    "a, b = np.polyfit(x, y, 1)\n",
    "\n",
    "#add points to plot\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "\n",
    "#add line of best fit to plot\n",
    "plt.plot(x, a*x+b, c=\"red\")       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our plot, the blue dots represent our data and the red line is the best line we can draw that reproduces the behavior of our data. Our LHCb data is not as simple as this example, but the idea is the same! We want to find the best curve that reproduces the shape of the mass distribution we found. It won't be a straight line as our data does not have this kind of pattern, but there are other types of functions that we can use.\n",
    "\n",
    "### Exponential function\n",
    "\n",
    "One very commonly used to measure lifetime is the exponential function. We can represent it by the function:\n",
    "\n",
    "$f(x) = A e^{(-tx)}$\n",
    "\n",
    "And if we want to draw this function, we can run the following line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## generate the data and plot it for a decreasing exponential curve\n",
    "\n",
    "## x-axis for the plot\n",
    "x_data = np.arange(-5, 5, 0.001)\n",
    "\n",
    "## y-axis as the decreasing exponential\n",
    "y_data = np.exp(-x_data)\n",
    "\n",
    "## plot data\n",
    "plt.plot(x_data, y_data)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Decreasing Exponential Curve')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to fit our real LHCb data with this function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Your data (assuming D0_full[\"D0_TAU\"] is a NumPy array or Pandas Series)\n",
    "data = D0_full[\"D0_TAU\"].values\n",
    "\n",
    "# Weights from the \"EvtType\" column\n",
    "weights = D0_full[\"EvtType\"].values\n",
    "\n",
    "# Define the number of bins and the range for the histogram\n",
    "num_bins = 60\n",
    "full_hist_range = [0, 0.01]\n",
    "fit_range = [.00025, 0.003]  # The range for fitting\n",
    "\n",
    "# Calculate the full histogram values and bin edges with weights\n",
    "full_hist_values, bin_edges = np.histogram(data, bins=num_bins, range=full_hist_range, weights=weights)\n",
    "\n",
    "# Calculate the bin centers from bin edges (for fitting purposes)\n",
    "bin_centers = 0.5 * (bin_edges[1:] + bin_edges[:-1])\n",
    "\n",
    "# Select only the data points within the fit range for curve fitting\n",
    "fit_mask = (bin_centers >= fit_range[0]) & (bin_centers <= fit_range[1])\n",
    "fit_data_x = bin_centers[fit_mask]\n",
    "fit_data_y = full_hist_values[fit_mask]\n",
    "\n",
    "# Define the decreasing exponential function for fitting\n",
    "def decreasing_exp(x, amplitude, decay_rate):\n",
    "    return amplitude * np.exp(-decay_rate * x)\n",
    "\n",
    "# Fit the function to the selected data points with weights\n",
    "fit_params, _ = curve_fit(decreasing_exp, fit_data_x, fit_data_y, p0=[max(fit_data_y), 1])\n",
    "\n",
    "# Retrieve the optimized parameters\n",
    "amplitude_fit, decay_rate_fit = fit_params\n",
    "\n",
    "# Print the fitted parameters\n",
    "print(\"Fitted Amplitude:\", amplitude_fit)\n",
    "print(\"Fitted Decay Rate:\", decay_rate_fit)\n",
    "\n",
    "# Generate x values for the full fitted curve\n",
    "x_fit_full = np.linspace(full_hist_range[0], full_hist_range[1], 1000)\n",
    "\n",
    "# Calculate the y values for the full fitted curve using the optimized parameters\n",
    "y_fit_full = decreasing_exp(x_fit_full, amplitude_fit, decay_rate_fit)\n",
    "\n",
    "# Plot the histogram with the full fitted curve\n",
    "plt.bar(bin_centers, full_hist_values, width=(full_hist_range[1] - full_hist_range[0]) / num_bins, edgecolor=\"black\", label=\"Histogram\")\n",
    "plt.plot(x_fit_full, y_fit_full, 'r-', label=\"Fitted Curve (Full Range)\")\n",
    "plt.xlabel(\"D0_TAU\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.yscale('log')\n",
    "plt.title(\"Histogram of D0_TAU with Fitted Decreasing Exponential Curve (Full Range)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we've just calculated the decay rate, we can obtain the lifetime following the relation:\n",
    "\n",
    "$\\tau = \\frac{1}{\\Gamma}$,\n",
    "\n",
    "where $\\Gamma$ is the decay rate, and $\\tau$ is the desired lifetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LT = 1/decay_rate_fit\n",
    "print(f'Lifetime = {LT} [s]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "__Congratulations!__ If everything went well, you have just calculated the lifetime of the $D^0$ meson!\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
